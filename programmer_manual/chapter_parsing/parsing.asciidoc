== Recursive descent parser

When i was studying compilers in university, i did not like yacc to implement
parsers, i used it to development a Java compiler and i think a descent parser
would be more suitable for that purpose.
indexterm:[yacc]
indexterm:[java]
Yacc uses LALR http://en.wikipedia.org/wiki/LALR_parser, the parser must decide
what rule use with only 1 token.

This code:
[code, c]
----
int a;
int f(void);
----

Have 2 lines starting with the same token, in yacc that would be a problem,
therefore  Abidos is an experiment about do a descent parser of a complex
language (C++), using backtracking http://en.wikipedia.org/wiki/Backtracking
to explore different rules that begin with the same token
indexterm:[descent parser]
indexterm:[Backtracking]

=== Classes

These are the most important classes of this component.

.c_parser UML diagram 1
image::images/chapter_parsing_c_parser_uml_01.{eps_svg}[align="center"]

c_context class is a *key part* of Abidos, for each node in the
*annotated parse tree*
indexterm:[c_context]

.c_parser UML diagram 2
image::images/chapter_parsing_c_parser_uml_02.{eps_svg}[align="center"]

Parser use this class all the time to get knowledge about tokens and too restore
states in the backtracking process.

=== Debugging Abidos

In order to see how Abidos works we will use gdb to trace an Abidos execution,
in this session i introduce you some topics that will be explained more deeply
in next chapters: context, translation rules from bison to descent form ...

Abidos have an X file, it is used for debugging purposes with gdb:

----
dir .
set print address off
b main
run --includes test_includes/ \
    --out_dir test_out/ \
    --test_all_tokens_consumed_flag \
    --test_original \
    --ts_show \
    --verbose --verbose test/book_01.cpp > test_out/out_book_01.cpp.txt
----

indexterm:[X file]
indexterm:[gdb]

We will use the same previous example:

Example
----
int a;
----

Remember the tree graph with more than 40 nodes generated, and will see how
abidos parses this and why the tree is so big.

Execute Abidos with gdb like this:
----
abidos/processor$ gdb src/abidos -x X
----

[NOTE]
====
I like use X file, in this way i have all the begin commands in the file and is
more easy execute gdb the next day.
====

First the loader starts to work looking what files Abidos will parse.

The parser starts to work in this line of main.cpp:

----
c_parser_descent parser;

parser.yyparse(file_name);
----

yyparser() function do:

[NOTE]
====
We will see here the most important rules from the parser tree, in the figure of
trace tree there are more rules where Abidos can not match tokens.
====

* lex_file_init().

* a set of the ts (symbols table).
//  ### explain with a UML diagram of TS classes

* And calls *translation_unit()* the fist rule of C++ Grammar
----
    c_trace_node trace_node; <1>
    trace_node.set("translation_unit"); <2>

    tokens_vector_clear(); <3>

    if (1 == declaration_seq_opt(trace_node)) { <4>
        return 1;
    }
    ...
----
<1> Here starts the trace tree.
<2> With this trace system, Abidos knows which node is using in each step.
<3> This is the main rule of the grammar we start with a fresh tokens_vector.
<4> in the grammar appears "translation_unit: declaration_seq_opt;" and here is
how write this rule in descent form is quite easy.

//if i don not put this paragraph the next bullet appears tabulated :-(

* declaration_seq_opt rule.

* declaration_seq.
----
declaration_seq: declaration | declaration_seq declaration ;
----

I translated this to the descent form:

----
int c_parser_descent::declaration_seq(c_trace_node trace_node)
{
    trace_graph.add(trace_node, "declaration_seq");

    int result = 0;

    while (1 == declaration(trace_node)) {
        tokens_vector_clear();
        result = 1;
    }

    return result;
}
----

In a descent parser we can not have left recursion (in yacc we can and we want 
it)

[NOTE]
====
I clear the vector of tokens here, i think there is safe and not more
backtracking will bee work with these tokens.
====


* Abidos goes to declaration rule

Here we can see in the trace tree how Abidos enters in the rules:
is_eof, extern_c, preprocessor, template_declaration and can not match the
actual token *int*

the original rule is
----
declaration: block_declaration | function_definition |
  template_declaration | explicit_instantiation | explicit_specialization
  | linkage_specification | namespace_definition ;
----

i write it with changing his order of son rules because block_declaration is
more cost to check it and i had to add some rules of my own:

1) is_eof, check if we are in the end of the file (we can cut the descent here).

2) preprocessor, in the original grammar do not have this rule, C++ have a
external preprocessor and works before compile do, but Abidos do this sort of
things in compile phase.

//

* block_declaration rule.

* simple_declaration, this is a kind of rule not than easy than previous
----
  if ( CLASS_SPECIFIER_STATUS_MEMBER_SPECIFIER
        != context.class_specifier_status ) {
    semantic.clear_decl_specifier();
  }
----

This lines are to know if Abidos is parsing a declaration inside a class scope
or not, lets see this with a little example:

----
class A{
  int a;
  int f(int i);
}
----

When Abidos parses *int a;* this will be a part of A class like an attribute,
but when Abidos are parsing *int i* this will be a part of *f* declaration not a
part of A directly, this 2 variables *a* and *i* are parsed in the same rules
and with the context Abidos know what they are.
indexterm:[context]

[NOTE]
====
context allow Abidos to know where he is, and what is the semantic value of a
token.
====

* decl_specifier_seq_opt

* decl_specifier_seq, a little hack in this rule to put in descent way,
the original rule in left recursion fashion is:
----
decl_specifier_seq: decl_specifier_seq_opt decl_specifier;
----

There is a indirect recursion by left calling *decl_specifier_seq_opt* and
this call decl_specifier_seq again. The goal of this recursion is iterating
*decl_specifier* for example "long int ...", if i would write this rule exact
like his original form i will have a stack overflow like this:

----
//
// i drop the indirect recursion for establish a clear example
// the execution is quite similar
//
int decl_specifier_seq(void)
{
  decl_specifier_seq(); <1>
  decl_specifier(); <2>
}
----
<1> program call this one time, and again and again ... until stack overflow.
<2> program never reach this line

The easy solution taken in Abidos is:
----
    while (1 == decl_specifier(trace_node)) { <1>
        result = 1;
    }
----
<1> iteration over *decl_specifier* reached with a while.

* decl_specifier, here we can see another trick
----
    const int vector_id[]={';' , ')', COLONCOLON,IDENTIFIER, '~', '#', -1};
    if (preanalisys_has_one(  vector_id,trace_node) ) {
        return 0;
    }
----

With this lines of code we can *prune* sub-trees and Abidos save resources
in this rule we know that a *decl* can not be a *#* or a *;* therefore if some
of this symbols are present we prune and does not get more deep.
indexterm:[preanalisys_has_one]
indexterm:[prune]

* type_specifier

* simple_type_specifier, here is a lot of things but where *int* is matched is
in this lines

----
    const int vector_id[]={
        CHAR, WCHAR_T, BOOL, SHORT, INT, LONG
        , SIGNED, UNSIGNED, FLOAT, DOUBLE, VOID, -1
    };

    if (token_is_one(vector_id,trace_node) != 0) { <1>
        result = 1;
    }
----
<1> *int* is matched here and this method, this method calls *is_one* and this
calls trace_graph.token_is_add here.

Then there are a lot of code about scopes of classes and templates parsing that
will see forward for this example is not used.

Abidos put the decl *int* in the semantic class.

----
  semantic.push_back_vector_decl_specifier(decl);
----

And this rule returns 1 indicating success, and In this case int should
be consumed therefore *context = context_tokens.restore();* are not used
to restore the context and forcing to process *int* again with other rules.

* decl_specifier_seq, Abidos try to iterates again with decl_specifier but
now *i* token is an IDENTIFIER.

* init_declarator_list_opt

* init_declarator_list, in this rule we can see another trick to development
rules in descent form:

----
    c_context_tokens context_tokens(context); <1>
    c_context_tokens context_good_way(context); <2>
----

<1> here Abidos save context to restore it if the rule don not match the token.
<2> here is another context saver in a declaration.

Lets see this last point C++ allows to put 1 or more, IDENTIFIERS separated by
*,* for example

----
  int a, b, c;
----

I use *;* like a terminator for this rule but i should restore put the token *;*
on the context queue again to be parsed in *simple_declaration* rule, for that
is this if:

----
        if ( token_is(';', trace_node) ) {
            // yes i restore here to consume ';' more up in the tree
            context = context_good_way.restore();
            return 1;
        }
----

And Abidos prune this rule with that.

[NOTE]
====
I would use *preanalisys_has_one* to do this prune but is a little more
inefficiency because it saves and restores the context in each check.
====

indexterm:[prune]
indexterm:[context_good_way]

* init_declarator

* declarator

* direct_declarator, there are a lot of code here but in this case it calls
next rule.

* declarator_id, this rule is uses to declare constructors too, but now it calls
next rule.
indexterm:[constructor]

* id_expression

* unqualified_id, this rule is used to declare destructors, but now it calls
next rule.
indexterm:[destructor]

* identifier, Abidos put the identifier in the semantic

----
  semantic.identifier(context, c_token_get());
----

=== Meaningful parts of parser

Now we can go to see what parts have Abidos parser to do his work, all these
are the core of the project and understand them is a *must* to begin to hack
Abidos.

Parser function token_next uses yylex() function to get tokens from lexer, but
parser needs a buffer to store these tokens and tokens_vector is that buffer. To
explain this more deeply lets see an example.
indexterm:[yylex]
indexterm:[tokens_vector]

Abidos have a big grammar because C++ is a complex language, the first step is
hack that grammar and do a little grammar in order to have a clear explanation,
the mechanics of the whole set of Abidos rules are the same. we will work with
this little grammar:

.little grammar
----
S->VARIABLE|FUNCTION
VARIABLE->int <IDENTIFIER>;
FUNCTION->int <IDENTIFIER>();
----

this grammar can match expressions like these:

.expressions matched by little grammar
----
int i;
int f();
----

We can translate these rules to Abidos fashion and the result is these method
rules of parser:

* S rule

Has the initialization of the trace system and the calls to the other rules.

[code, c]
----
int c_parser_descent::S(void)
{
    c_trace_node trace_node; <1>

    trace_node.set("S");

    tokens_vector_clear(); <2>

    if (1 == VARIABLE(trace_node)) { <3>
        return 1;
    }

    if (1 == FUNCTION(trace_node)) {
        return 1;
    }

    return 0;
}
----

<1> here is where trace tree begins, with this tree we will see the rules used
by Abidos to parser an example.

<2> parser uses this vector like a buffer between lexer and himself, it will
full explained in a moment.

<3> this is the codification of a rule like *VARIABLE->int <IDENTIFIER>;*.

//
* VARIABLE rule

This rule tries to match expressions like *int i;*.

[code, c]
----
int c_parser_descent::VARIABLE(c_trace_node trace_node)
{
    trace_graph.add(trace_node, "VARIABLE"); <1>
    c_context_tokens context_tokens(context); <2>

    token_next(trace_node.get_tab()); <3>
    if ( token_is_not(INT, trace_node) ) { <4>
        context = context_tokens.restore(); <5>
        return 0;
    }

    token_next(trace_node.get_tab());
    if ( token_is_not(IDENTIFIER, trace_node) ) {
        context = context_tokens.restore();
        return 0;
    }

    token_next(trace_node.get_tab());
    if ( token_is_not(';', trace_node) ) {
        context = context_tokens.restore();
        return 0;
    }

    return 1;
}
----
<1> this is how trace system knows what rule is working.

<2> here we save the context in the point 5 we will see why is important.

<3> in this function parser read a token from the buffer or from the lexer.

<4> this is the way to check if the actual token is an *INT*.

<5> suppose the token read is *VOID* we need restore the context in order to can
read *VOID* in other rule if we do not restore the context we would lose the
actual token.

//
* FUNCTION rule

This rule tries to match expressions like *int f();*.

[code, c]
----
int c_parser_descent::FUNCTION(c_trace_node trace_node)
{
    trace_graph.add(trace_node, "FUNCTION");
    c_context_tokens context_tokens(context);

    token_next(trace_node.get_tab());
    if ( token_is_not(INT, trace_node) ) {
        context = context_tokens.restore();
        return 0;
    }

    token_next(trace_node.get_tab());
    if ( token_is_not(IDENTIFIER, trace_node) ) {
        context = context_tokens.restore();
        return 0;
    }

    token_next(trace_node.get_tab());
    if ( token_is_not('(', trace_node) ) {
        context = context_tokens.restore();
        return 0;
    }

    token_next(trace_node.get_tab());
    if ( token_is_not(')', trace_node) ) {
        context = context_tokens.restore();
        return 0;
    }

    token_next(trace_node.get_tab());
    if ( token_is_not(';', trace_node) ) {
        context = context_tokens.restore();
        return 0;
    }

    return 1;
}
----

This rule is pretty similar to the previous one except in this rule we need
match *(* and *)* before *;*.

Lets see an example of a variable declaration:

[code, c]
----
int i;
----

We can see how all the tokens are matched in the VARIABLE rule.

.variable trace tree
image::images/chapter_parsing_trace_book_little_grammar_variable.cpp.{eps_svg}[align="center"]

Now lets see an example of a function declaration:

[code, c]
----
int f();
----

now the VARIABLE rule does not match all the tokens and Abidos executes the
another rule FUNCTION.

.function trace tree
image::images/chapter_parsing_trace_book_little_grammar_function.cpp.{eps_svg}[align="center"]

When Abidos executes VARIABLE rule here get from lexer the tokens *int f (* and
stores these in *tokens_vector* a buffer queue each time *token_next* is called,
when VARIABLE rule tries to
match *(* like a *;* fails and restore context when FUNCTION rule starts to work
token_next use *tokens_vector* to get the tokens starting in *context.i_token*
therefore *int f (* are processed another time, when *(* is read the next time
token_next is called it calls *yylex()* to obtain *)* from lexer
because *context.i_token* reaches the end of *tokens_vector*.
indexterm[tokens_vector]
indexterm[i_token, context.i_token]
indexterm[context.restore, restore]

In the next diagram we can see how S calls VARIABLE rule and inside of the rule
execute the *token_next()* in order to obtain the tokens from lexer and putting
them in the queue *tokens_vector*.

.token_next() calls and buffer changes
image::images/chapter_parsing_token_next_buffer_01.{eps_svg}[align="center"]

[NOTE]
====
context.i_token have i_token which is an index to the actual token and when
restore() is called *context.i_token* points to *int* again and then FUNCTION rule
can parse the same tokens and ")" ";" too.
====

//

